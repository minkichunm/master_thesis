{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf318b02-028e-4235-9f03-048a7d41e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set module auto-reloaded \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01627cc9-b85e-4bd4-a4de-74e37afc4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import dahuffman\n",
    "import pickle\n",
    "from Compressible_Huffman import Huffman\n",
    "from getModel import get_simplemodel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c02018-fbc7-4b1a-8988-97c9aa95f7d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b9adb4a2c185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcompNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcompNN_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mdecompressed_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompressNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompressed_model_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mdecompressed_weights_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ThesisProject/master_thesis/Compressible_Huffman.py\u001b[0m in \u001b[0;36mdecompressNN\u001b[0;34m(self, compressed_weights)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mdecompressed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompressed_data\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use decode() directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mweight_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[0;31m# Retrieve the shape of the corresponding weight tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mdecompressed_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get_weights'"
     ]
    }
   ],
   "source": [
    "# Load the CompressibleNN instance\n",
    "import os\n",
    "\n",
    "compNN_list = []\n",
    "cnt = 0\n",
    "directory = 'results_cifar_s'\n",
    "decompressed_weights_list = []\n",
    "\n",
    "while True:\n",
    "    # Check if the file exists\n",
    "    filename = f'{directory}/compressed_nn_{cnt}.pkl'\n",
    "    if not os.path.exists(filename):\n",
    "        break\n",
    "\n",
    "    # Load the compressed model from the file\n",
    "    with open(filename, 'rb') as compressed_nn:\n",
    "        net_model = pickle.load(compressed_nn)\n",
    "        codec = pickle.load(compressed_nn)\n",
    "        compressed_model_weights = pickle.load(compressed_nn)\n",
    "\n",
    "    # Create a new instance of CompressibleNN\n",
    "    compNN = Huffman(net_model)\n",
    "    compNN.codec = codec\n",
    "    compNN_list.append(compNN)\n",
    "    decompressed_weights = compNN.decompressNN(compressed_model_weights)\n",
    "    decompressed_weights_list.append(decompressed_weights)\n",
    "    \n",
    "    # Increment the counter\n",
    "    cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc8fc49-f1eb-4d8a-a1d3-881c8c25ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "# Compare the original weights with the decompressed weights\n",
    "original_model_weights_list = []\n",
    "for cnt, compNN in enumerate(compNN_list):\n",
    "    # Check if the file exists\n",
    "    filename = f'{directory}/original_model{cnt}_weights.pkl'\n",
    "    if not os.path.exists(filename):\n",
    "        break\n",
    "    with open(filename, 'rb') as file:\n",
    "        original_model_weights = pickle.load(file)\n",
    "    original_model_weights_list.append(original_model_weights)\n",
    "        \n",
    "    differences = compNN.compare_weights(original_model_weights_list[cnt], decompressed_weights_list[cnt])\n",
    "\n",
    "    print(f\"Differences between original and decompressed weights in model{cnt}:\")\n",
    "    for i, diff in enumerate(differences):\n",
    "        print(f\"Layer {i+1}: Max Difference = {np.max(diff)}, Mean Difference = {np.mean(diff)}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05208ae-d77c-4b8a-95ed-908b2b11f170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set decompressed weights\n",
    "for compNN, decompressed_weights in zip(compNN_list, decompressed_weights_list):\n",
    "    compNN.set_weights(decompressed_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c09e2dc-334b-4f87-a346-5d93d4a8ff92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 7840000 into shape (28,28,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cb45137e067a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Keep the shape (None, 28, 28, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Keep the shape (None, 28, 28, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    297\u001b[0m            [5, 6]])\n\u001b[1;32m    298\u001b[0m     \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 7840000 into shape (28,28,3)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "image_size = x_train.shape[1] # 28\n",
    "input_size = image_size * image_size\n",
    "\n",
    "# Preprocess the data (reshape and normalize)\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 3])  # Keep the shape (None, 28, 28, 1)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 3])  # Keep the shape (None, 28, 28, 1)\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "results = []\n",
    "\n",
    "for cnt, compNN in enumerate(compNN_list): \n",
    "    # Make predictions using your model\n",
    "    predictions = compNN.predict(x_test)\n",
    "\n",
    "    # Calculate top-1 accuracy\n",
    "    predicted_labels = tf.argmax(predictions, axis=1)\n",
    "    top_1_accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted_labels, y_test), tf.float32)) * 100\n",
    "\n",
    "    print(f\"Model{cnt} Top-1 Accuracy: {top_1_accuracy:.3f}%\")\n",
    "    results.append(f\"Model{cnt} Top-1 Accuracy: {top_1_accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4cc93dd5-cdee-4229-b7e6-803f87e54a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the full path to the log file\n",
    "log_filename = os.path.join(directory, \"accuracy_logs.txt\")\n",
    "\n",
    "# Save the results to the file\n",
    "with open(log_filename, \"w\") as file:\n",
    "    for result_entry in results:\n",
    "        file.write(result_entry + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
