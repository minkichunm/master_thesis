{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e6082-2e87-43d9-8038-5e1ce0b3ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Steps of the work:\n",
    "\n",
    "# Make a model with accessible parameters using TensorFlow 2.x\n",
    "# Write an entropy loss and add it to the network parameters for training.\n",
    "# Train a model by jointly optimizing its loss (e.g. cross entropy for classification) and the entropy for compressability.\n",
    "# Compress the model parameters using Huffman coding.\n",
    "# Analyze the results and trade-off between accuracy and compressability.\n",
    "# Write a model wrapper that can read and write the compressed parameters.\n",
    "\n",
    "# Notes:\n",
    "\n",
    "# Can be started on simple datasets like MNIST.\n",
    "# Can start from simple MLP NNs. And then extend to convs. The implementation should be generic enough so that it can support any layer.\n",
    "# Bonus: add support for normalization layers: batch norm, instance norm, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83f182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar10 data set\n",
    "\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# train_set, test_set = mnist.load_data()\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dfd2bf9-4e53-4afb-aefc-2255be6162bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# Allocation of 17179869184 exceeds 10% of free system memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49010b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a simple NN model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU\n",
    "\n",
    "    \n",
    "kernel_initializer = 'he_normal'\n",
    "\n",
    "def get_model(chs=128):\n",
    "#     shape=(32, 32, 3)\n",
    "    shape=(32,32,64)\n",
    "#         shape=(32,32,128)\n",
    "#     shape=(16,16,256) \n",
    "# shape=(8,8,256)\n",
    "# shape=(4,4,256)\n",
    "#     reduce shape increase channel\n",
    "# dont do batch\n",
    "# stride\n",
    "# do step by step\n",
    "# run by hpc\n",
    "\n",
    "# different mlp layer, cnn\n",
    "# \n",
    "    \n",
    "    inputs = Input(shape)\n",
    "    layer = Conv2D(chs * 2, (3, 3), padding='same', kernel_initializer=kernel_initializer)(inputs)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = ReLU()(layer)\n",
    "    \n",
    "    layer = Conv2D(chs, (3, 3), padding='same', kernel_initializer=kernel_initializer)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = ReLU()(layer)\n",
    "    \n",
    "    layer = Flatten()(layer)\n",
    "    print(layer)\n",
    "    output = Dense(10, activation='linear', use_bias=True, kernel_initializer=kernel_initializer)(layer)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a97452-e7b2-4971-a406-e45a853c56fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 256)       7168      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 256)      1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 128)       295040    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1310730   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,614,474\n",
      "Trainable params: 1,613,706\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "991b1111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 131072), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n"
     ]
    }
   ],
   "source": [
    "#     To estimate the histogram, we first remove outliers in the\n",
    "# activations if the samples are outside the range [μ−3σ; μ+3σ]\n",
    "from histogram import calculate_histogram, test_histogram, calculate_histogram_range\n",
    "\n",
    "def calculate_entropy(variables, eps=0.0):\n",
    "    min_h, max_h = calculate_histogram_range(variables)\n",
    "    flat_vars = tf.reshape(variables, (-1,1))    \n",
    "    hist = calculate_histogram(flat_vars, min_h, max_h)\n",
    "    \n",
    "    probs = hist / tf.reduce_sum(hist)\n",
    "    entropy = -tf.reduce_sum(probs * tf.experimental.numpy.log2(probs+eps))\n",
    "    return entropy, (min_h, max_h)\n",
    "\n",
    "\n",
    "def calc_sparsity_regularization(inputs, regularization_coefficient=1e-2):\n",
    "    abs_inputs = tf.abs(inputs)\n",
    "    l1_norm = tf.reduce_sum(abs_inputs, axis=0)\n",
    "    num_activations = tf.cast(tf.shape(inputs)[0], dtype=tf.float32)\n",
    "    regularization_loss = regularization_coefficient / num_activations * tf.reduce_sum(l1_norm)\n",
    "    \n",
    "    return regularization_loss\n",
    "\n",
    "class CompressibleNN(keras.Model):\n",
    "    def __init__(self, net_model):\n",
    "        super(CompressibleNN, self).__init__()\n",
    "        self.net_model = net_model\n",
    "        self.CE_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.net_model(inputs)\n",
    "    \n",
    "    def entropy_loss(self, inputs):\n",
    "        entropy = 0\n",
    "        \n",
    "        for l in self.net_model.layers:\n",
    "            if isinstance(l, keras.layers.Dense):\n",
    "                for v in l.trainable_variables:\n",
    "                    v_entropy, v_range = calculate_entropy(v)\n",
    "                    entropy += v_entropy\n",
    "        return entropy\n",
    "    \n",
    "    def regularization_loss(self, inputs):\n",
    "        rg_loss = 0\n",
    "        \n",
    "        for l in self.net_model.layers:\n",
    "            if isinstance(l, keras.layers.Dense):\n",
    "                for v in l.trainable_variables:\n",
    "                    v_regularization_loss = calc_sparsity_regularization(v)\n",
    "                    rg_loss += v_regularization_loss\n",
    "\n",
    "        return rg_loss\n",
    "    \n",
    "    \n",
    "    def train_step(self, input):\n",
    "        images = input[0]\n",
    "        labels = input[1]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self.net_model(images)\n",
    "            loss =  self.entropy_loss(images)\n",
    "            regularization_loss = self.regularization_loss(images)\n",
    "\n",
    "        # Get the gradients w.r.t the loss\n",
    "        gradient = tape.gradient(loss, self.net_model.trainable_variables)\n",
    "#         gradient_reg = tape.gradient(regularization_loss, self.net_model.trainable_variables)\n",
    "        # Update the weights using the generator optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradient_reg, self.net_model.trainable_variables)\n",
    "        )\n",
    "#         return {\"regularization loss\": regularization_loss}\n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "model = get_model()\n",
    "\n",
    "compNN = CompressibleNN(model)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=1e-3, beta_1=0.9)\n",
    "compNN.compile(optimizer, loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd59b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 07:59:14.424835: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1342177280 exceeds 10% of free system memory.\n",
      "2023-06-26 07:59:15.114143: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1342177280 exceeds 10% of free system memory.\n",
      "2023-06-26 07:59:16.148544: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1342177280 exceeds 10% of free system memory.\n",
      "2023-06-26 07:59:17.848082: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1342177280 exceeds 10% of free system memory.\n",
      "2023-06-26 07:59:20.678313: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1342177280 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "# loss needs to be decreased during training\n",
    "compNN.fit(x=x_train, y=y_train, epochs=1, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22f9f5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:  96.02000000000001\n"
     ]
    }
   ],
   "source": [
    "# test performance\n",
    "res = model(test_set[0])\n",
    "print(\"test acc: \", 100*(np.argmax(res, axis=1)==test_set[1]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea567bd1-7137-49cd-9824-36e918ad0b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:  96.61\n"
     ]
    }
   ],
   "source": [
    "# test performance with entropy_loss\n",
    "res = model(test_set[0])\n",
    "print(\"test acc: \", 100*(np.argmax(res, axis=1)==test_set[1]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4cfb0d-21e8-40bf-97ab-e23562acfdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    " 17.7708\n",
    " 17.7171\n",
    " 17.6588\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
