{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bac1626-10ac-471d-b6af-9ce965992393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.5940590e-02, -4.0624756e-02, -4.1460260e-03, ...,\n",
       "         -4.8734844e-02,  1.9328283e-02, -4.8259225e-02],\n",
       "        [-3.1265214e-02,  8.2980007e-02,  4.3803539e-02, ...,\n",
       "          3.1056687e-02,  1.7932033e-02,  6.9596302e-03],\n",
       "        [ 4.3348661e-03, -5.9631437e-02, -1.1196332e-01, ...,\n",
       "          9.3319051e-02,  5.8863158e-03,  2.1785971e-02],\n",
       "        ...,\n",
       "        [ 3.3533853e-02,  6.6992859e-03, -6.3023791e-03, ...,\n",
       "          2.3112213e-02,  4.6645924e-02, -7.4068695e-02],\n",
       "        [ 7.1984477e-02, -3.1879887e-02, -2.1005819e-02, ...,\n",
       "          8.7428585e-02, -3.9414110e-05,  5.2459769e-02],\n",
       "        [-1.4843541e-02,  1.2660646e-02,  6.5805893e-03, ...,\n",
       "          9.9764671e-03, -1.6177995e-02, -7.8036278e-02]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32),\n",
       " array([[-0.01406196, -0.06694973, -0.02813871, ...,  0.09715012,\n",
       "          0.06567784, -0.1035566 ],\n",
       "        [-0.03199501, -0.06869922,  0.00943725, ..., -0.0126965 ,\n",
       "         -0.05781977,  0.11177838],\n",
       "        [-0.0111015 , -0.0226028 , -0.07339984, ...,  0.08544662,\n",
       "          0.02045189, -0.13047066],\n",
       "        ...,\n",
       "        [ 0.0330387 ,  0.0754226 , -0.00568872, ...,  0.07630368,\n",
       "         -0.18989599, -0.0165139 ],\n",
       "        [ 0.03642752, -0.06067944, -0.08067384, ...,  0.03861352,\n",
       "          0.07882054, -0.09756422],\n",
       "        [-0.10850835, -0.06362432,  0.09448847, ..., -0.13742861,\n",
       "          0.06380027,  0.08377494]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.13238728, -0.06846547,  0.08727671, ..., -0.05447387,\n",
       "         -0.05245318,  0.161668  ],\n",
       "        [-0.12525788,  0.01303198,  0.02341274, ..., -0.01739996,\n",
       "         -0.20449057, -0.2752485 ],\n",
       "        [-0.092122  , -0.18306144, -0.20125017, ...,  0.10188552,\n",
       "         -0.05400479, -0.06459513],\n",
       "        ...,\n",
       "        [-0.1000002 ,  0.13811195,  0.1069814 , ...,  0.17162716,\n",
       "          0.20827053, -0.10186215],\n",
       "        [-0.02188365, -0.05137156, -0.18566918, ..., -0.18156365,\n",
       "         -0.00077623, -0.13396132],\n",
       "        [ 0.20654467,  0.00132197,  0.2431891 , ..., -0.14191724,\n",
       "         -0.20257828,  0.23533487]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('original_model_weights.pkl', 'rb') as file:\n",
    "    original_model_weights = pickle.load(file)\n",
    "\n",
    "original_model_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211d8094-8f4e-49aa-a9a8-2cb29f4577f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('compressed_model_weights.pkl', 'rb') as file:\n",
    "    compressed_model_weights = pickle.load(file)\n",
    "\n",
    "# compressed_model_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a33808e0-4925-4d76-96ba-4f02983a0be9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model()\n\u001b[1;32m     30\u001b[0m compNN \u001b[38;5;241m=\u001b[39m CompressibleNN(model)\n\u001b[0;32m---> 31\u001b[0m decompressed_weights \u001b[38;5;241m=\u001b[39m \u001b[43mcompNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompressNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompressed_model_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(compressed_weights)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(decompressed_weights)\n",
      "File \u001b[0;32m/workspace/Compressible_Huffman.py:44\u001b[0m, in \u001b[0;36mCompressibleNN.decompressNN\u001b[0;34m(self, compressed_weights)\u001b[0m\n\u001b[1;32m     42\u001b[0m decompressed_weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, compressed_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(compressed_weights):\n\u001b[0;32m---> 44\u001b[0m     decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodec\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     45\u001b[0m     decompressed_data \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(compressed_data)  \u001b[38;5;66;03m# Use decode() directly\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecompressed data size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(decompressed_data))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/data_structures.py:434\u001b[0m, in \u001b[0;36mList.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 434\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import dahuffman\n",
    "import pickle\n",
    "from Compressible_Huffman import CompressibleNN\n",
    "\n",
    "\n",
    "kernel_initializer = 'he_normal'\n",
    "activation = \"relu\"\n",
    "\n",
    "\n",
    "def get_model(chs=128):\n",
    "    shape = (28, 28, 1)\n",
    "\n",
    "    inputs = Input(shape)\n",
    "    layer = Flatten()(inputs)\n",
    "    layer = Dense(units=chs * 2, activation=activation, kernel_initializer=kernel_initializer)(layer)\n",
    "    layer = Dense(units=chs, activation=activation, kernel_initializer=kernel_initializer)(layer)\n",
    "    output = Dense(10, activation='linear', use_bias=True, kernel_initializer=kernel_initializer)(layer)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    return model\n",
    "    \n",
    "\n",
    "model = get_model()\n",
    "\n",
    "compNN = CompressibleNN(model)\n",
    "decompressed_weights = compNN.decompressNN(compressed_model_weights)\n",
    "\n",
    "print(compressed_weights)\n",
    "print(decompressed_weights)\n",
    "\n",
    "# Compare the original weights with the decompressed weights\n",
    "differences = compNN.compare_weights(original_model_weights, decompressed_weights)\n",
    "\n",
    "print(\"Differences between original and decompressed weights:\")\n",
    "for i, diff in enumerate(differences):\n",
    "    print(f\"Layer {i+1}: Max Difference = {np.max(diff)}, Mean Difference = {np.mean(diff)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cfd8f131-dfda-4311-835d-9bb192cbe580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Weight tensor shape: (784, 256)\n",
      "Weight tensor size: 200704\n",
      "Weight flattened size: 200704\n",
      "Compressed data size: 739794\n",
      "Weight tensor shape: (256,)\n",
      "Weight tensor size: 256\n",
      "Weight flattened size: 256\n",
      "Compressed data size: 128\n",
      "Weight tensor shape: (256, 128)\n",
      "Weight tensor size: 32768\n",
      "Weight flattened size: 32768\n",
      "Compressed data size: 121327\n",
      "Weight tensor shape: (128,)\n",
      "Weight tensor size: 128\n",
      "Weight flattened size: 128\n",
      "Compressed data size: 64\n",
      "Weight tensor shape: (128, 10)\n",
      "Weight tensor size: 1280\n",
      "Weight flattened size: 1280\n",
      "Compressed data size: 4701\n",
      "Weight tensor shape: (10,)\n",
      "Weight tensor size: 10\n",
      "Weight flattened size: 10\n",
      "Compressed data size: 5\n",
      "Decompressed data size: 802816\n",
      "Expected decompressed size: 802816\n",
      "Actual decompressed size: 802816\n",
      "Decompressed data size: 1024\n",
      "Expected decompressed size: 1024\n",
      "Actual decompressed size: 1024\n",
      "Decompressed data size: 131072\n",
      "Expected decompressed size: 131072\n",
      "Actual decompressed size: 131072\n",
      "Decompressed data size: 512\n",
      "Expected decompressed size: 512\n",
      "Actual decompressed size: 512\n",
      "Decompressed data size: 5120\n",
      "Expected decompressed size: 5120\n",
      "Actual decompressed size: 5120\n",
      "Decompressed data size: 40\n",
      "Expected decompressed size: 40\n",
      "Actual decompressed size: 40\n",
      "Differences between original and decompressed weights:\n",
      "Layer 1: Max Difference = 0.0, Mean Difference = 0.0\n",
      "Layer 2: Max Difference = 0.0, Mean Difference = 0.0\n",
      "Layer 3: Max Difference = 0.0, Mean Difference = 0.0\n",
      "Layer 4: Max Difference = 0.0, Mean Difference = 0.0\n",
      "Layer 5: Max Difference = 0.0, Mean Difference = 0.0\n",
      "Layer 6: Max Difference = 0.0, Mean Difference = 0.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import dahuffman\n",
    "\n",
    "\n",
    "class CompressibleNN(keras.Model):\n",
    "    def __init__(self, net_model):\n",
    "        super(CompressibleNN, self).__init__()\n",
    "        self.net_model = net_model\n",
    "        self.codec = []\n",
    "\n",
    "    def decompressNN(self, compressed_weights):\n",
    "        # Decompress the weights using Huffman coding\n",
    "        decompressed_weights = []\n",
    "        for i, compressed_data in enumerate(compressed_weights):\n",
    "            decoder = self.codec[i]\n",
    "            decompressed_data = decoder.decode(compressed_data)  # Use decode() directly\n",
    "\n",
    "            print(\"Decompressed data size:\", len(decompressed_data))\n",
    "            weight_shape = self.net_model.get_weights()[i].shape  # Retrieve the shape of the corresponding weight tensor\n",
    "            decompressed_size = np.prod(weight_shape) * np.dtype(np.float32).itemsize\n",
    "\n",
    "            print(\"Expected decompressed size:\", decompressed_size)\n",
    "            print(\"Actual decompressed size:\", len(decompressed_data))\n",
    "\n",
    "            if len(decompressed_data) < decompressed_size:\n",
    "                decompressed_data += b'\\x00' * (decompressed_size - len(decompressed_data))\n",
    "\n",
    "            elif len(decompressed_data) > decompressed_size:\n",
    "                decompressed_data = decompressed_data[:decompressed_size]\n",
    "\n",
    "            decompressed_array = np.frombuffer(bytes(decompressed_data), dtype=np.float32)\n",
    "            decompressed_weights.append(decompressed_array.reshape(weight_shape))\n",
    "\n",
    "        return decompressed_weights\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.net_model(inputs)\n",
    "\n",
    "    def reshape_weights(self, inputs):\n",
    "        reshaped_weights = []\n",
    "        current_index = 0\n",
    "        for weight_tensor in self.net_model.get_weights():\n",
    "            weight_shape = weight_tensor.shape\n",
    "            weight_size = np.prod(weight_shape)\n",
    "            # Reshape the weight tensor based on the size of the input array\n",
    "            reshaped_weights.append(weight_tensor.reshape(weight_shape))\n",
    "            current_index += weight_size\n",
    "        return reshaped_weights\n",
    "    \n",
    "    def compare_weights(self, original_weights, decompressed_weights):\n",
    "        differences = []\n",
    "        for orig, decomp in zip(original_weights, decompressed_weights):\n",
    "            orig_shape = orig.shape\n",
    "            decomp_shape = decomp.shape\n",
    "            decomp_reshaped = decomp.reshape(orig_shape) if orig_shape == decomp_shape else decomp\n",
    "            diff = np.abs(orig - decomp_reshaped)\n",
    "            differences.append(diff)\n",
    "        return differences\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "model = get_model()\n",
    "compNN = CompressibleNN(model)\n",
    "\n",
    "# Generate some random data for testing\n",
    "random_state = np.random.RandomState(42)  # Set the seed value to 42\n",
    "inputs = random_state.rand(28, 28, 1)  # Generate random input data\n",
    "\n",
    "# Compress the weights\n",
    "compressed_weights = compNN.compressNN(inputs)\n",
    "\n",
    "# Decompress the weights\n",
    "decompressed_weights = compNN.decompressNN(compressed_weights)\n",
    "\n",
    "# print(compressed_weights)\n",
    "# print(decompressed_weights)\n",
    "\n",
    "# Compare the original weights with the decompressed weights\n",
    "differences = compNN.compare_weights(model.get_weights(), decompressed_weights)\n",
    "print(\"Differences between original and decompressed weights:\")\n",
    "for i, diff in enumerate(differences):\n",
    "    print(f\"Layer {i+1}: Max Difference = {np.max(diff)}, Mean Difference = {np.mean(diff)}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b88df797-4c3b-4e9c-92c0-de727d2fd655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.0387225 , -0.08137392, -0.02914773, ..., -0.00919168,\n",
      "         0.02946452,  0.04639422],\n",
      "       [-0.05397551, -0.00483679, -0.04930591, ...,  0.07424383,\n",
      "         0.0271853 , -0.01563342],\n",
      "       [-0.00271451, -0.0424049 , -0.00124385, ...,  0.00815904,\n",
      "        -0.0186043 , -0.02493658],\n",
      "       ...,\n",
      "       [ 0.06878325,  0.03475486,  0.06290235, ...,  0.04817623,\n",
      "        -0.08055975,  0.05437632],\n",
      "       [-0.07352863,  0.01516827,  0.10736844, ..., -0.01694267,\n",
      "         0.06866149,  0.00142415],\n",
      "       [-0.03066814,  0.03886299,  0.03796422, ...,  0.08156086,\n",
      "         0.02407725, -0.06137323]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32), array([[-0.05473082, -0.08747619, -0.09267823, ...,  0.03438703,\n",
      "         0.05442026, -0.14908285],\n",
      "       [ 0.12407006, -0.06414388,  0.0274786 , ...,  0.08441756,\n",
      "         0.01513519, -0.10123061],\n",
      "       [ 0.14844115, -0.1502237 ,  0.09429957, ..., -0.16309366,\n",
      "        -0.07074652, -0.000291  ],\n",
      "       ...,\n",
      "       [ 0.02375787,  0.09773865,  0.07689589, ..., -0.03664695,\n",
      "         0.16372688,  0.12212976],\n",
      "       [-0.03579683,  0.0100025 , -0.02489873, ...,  0.09990413,\n",
      "        -0.1348389 , -0.01136187],\n",
      "       [ 0.15497929, -0.12766743,  0.03431471, ...,  0.03162755,\n",
      "         0.04003979,  0.00781596]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[-0.21259066, -0.01089567, -0.02497171, ...,  0.02639445,\n",
      "         0.06686264,  0.21426989],\n",
      "       [ 0.04711202,  0.05810664, -0.05675338, ...,  0.16335574,\n",
      "        -0.11026386,  0.03047448],\n",
      "       [-0.06761184, -0.17188099,  0.05826836, ..., -0.03980751,\n",
      "         0.16168733,  0.0682351 ],\n",
      "       ...,\n",
      "       [-0.00555486,  0.20761333,  0.00415648, ..., -0.02198105,\n",
      "         0.05630907, -0.02674305],\n",
      "       [ 0.15399532, -0.1474021 , -0.13314971, ...,  0.09355479,\n",
      "        -0.06023131,  0.0226844 ],\n",
      "       [ 0.11596036,  0.14716065, -0.0693124 , ..., -0.01054673,\n",
      "         0.07708199, -0.15401456]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7c472479-1619-49e5-a657-c71d91bfc7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.0387225 , -0.08137392, -0.02914773, ..., -0.00919168,\n",
      "         0.02946452,  0.04639422],\n",
      "       [-0.05397551, -0.00483679, -0.04930591, ...,  0.07424383,\n",
      "         0.0271853 , -0.01563342],\n",
      "       [-0.00271451, -0.0424049 , -0.00124385, ...,  0.00815904,\n",
      "        -0.0186043 , -0.02493658],\n",
      "       ...,\n",
      "       [ 0.06878325,  0.03475486,  0.06290235, ...,  0.04817623,\n",
      "        -0.08055975,  0.05437632],\n",
      "       [-0.07352863,  0.01516827,  0.10736844, ..., -0.01694267,\n",
      "         0.06866149,  0.00142415],\n",
      "       [-0.03066814,  0.03886299,  0.03796422, ...,  0.08156086,\n",
      "         0.02407725, -0.06137323]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0.], dtype=float32), array([[-0.05473082, -0.08747619, -0.09267823, ...,  0.03438703,\n",
      "         0.05442026, -0.14908285],\n",
      "       [ 0.12407006, -0.06414388,  0.0274786 , ...,  0.08441756,\n",
      "         0.01513519, -0.10123061],\n",
      "       [ 0.14844115, -0.1502237 ,  0.09429957, ..., -0.16309366,\n",
      "        -0.07074652, -0.000291  ],\n",
      "       ...,\n",
      "       [ 0.02375787,  0.09773865,  0.07689589, ..., -0.03664695,\n",
      "         0.16372688,  0.12212976],\n",
      "       [-0.03579683,  0.0100025 , -0.02489873, ...,  0.09990413,\n",
      "        -0.1348389 , -0.01136187],\n",
      "       [ 0.15497929, -0.12766743,  0.03431471, ...,  0.03162755,\n",
      "         0.04003979,  0.00781596]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[-0.21259066, -0.01089567, -0.02497171, ...,  0.02639445,\n",
      "         0.06686264,  0.21426989],\n",
      "       [ 0.04711202,  0.05810664, -0.05675338, ...,  0.16335574,\n",
      "        -0.11026386,  0.03047448],\n",
      "       [-0.06761184, -0.17188099,  0.05826836, ..., -0.03980751,\n",
      "         0.16168733,  0.0682351 ],\n",
      "       ...,\n",
      "       [-0.00555486,  0.20761333,  0.00415648, ..., -0.02198105,\n",
      "         0.05630907, -0.02674305],\n",
      "       [ 0.15399532, -0.1474021 , -0.13314971, ...,  0.09355479,\n",
      "        -0.06023131,  0.0226844 ],\n",
      "       [ 0.11596036,  0.14716065, -0.0693124 , ..., -0.01054673,\n",
      "         0.07708199, -0.15401456]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(decompressed_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a97a2-d1a3-4079-95d6-059adbe8ff63",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 3) (190610571.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[91], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 3)\n"
     ]
    }
   ],
   "source": [
    "Here is my neural network model like below\n",
    "\n",
    "\"\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import dahuffman\n",
    "    \n",
    "kernel_initializer = 'he_normal'\n",
    "activation = \"relu\"\n",
    "\n",
    "def get_model(chs=128):\n",
    "    shape=(28,28,1)\n",
    "    \n",
    "    inputs = Input(shape)\n",
    "    layer = Flatten()(inputs)\n",
    "    layer = Dense(units=chs*2, activation=activation, kernel_initializer=kernel_initializer)(layer)\n",
    "    layer = Dense(units=chs, activation=activation, kernel_initializer=kernel_initializer)(layer)\n",
    "    output = Dense(10, activation='linear', use_bias=True, kernel_initializer=kernel_initializer)(layer)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "class CompressibleNN(keras.Model):\n",
    "    def __init__(self, net_model):\n",
    "        super(CompressibleNN, self).__init__()\n",
    "        self.net_model = net_model\n",
    "\n",
    "    def compressNN(self, inputs):\n",
    "            # implement \n",
    "\n",
    "    def decompressNN(self, inputs):\n",
    "            # implement \n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.net_model(inputs)\n",
    "    \n",
    "    def compare_weights(self, original_weights, decompressed_weights):\n",
    "            # implement\n",
    "    \n",
    "model = get_model()\n",
    "compNN = CompressibleNN(model)\n",
    "\n",
    "# Generate some random data for testing\n",
    "random_state = np.random.RandomState(42)  # Set the seed value to 42\n",
    "\n",
    "\n",
    "# Compress the weights\n",
    "compressed_weights = compNN.compressNN(inputs)\n",
    "\n",
    "# Decompress the weights\n",
    "decompressed_weights = compNN.decompressNN(compressed_weights)\n",
    "\"\n",
    "\n",
    "\n",
    "I have a network model. I want compress it and decompress it. Put the weights back into the neural network. \n",
    "And then see the after compress and decompress and then match with the original.\n",
    "\n",
    "Can you implement function compressNN, decompressNN and ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9d934cf3-e0ff-496c-aeba-7e1ff0afe2d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "51",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m compressed_weights \u001b[38;5;241m=\u001b[39m compNN\u001b[38;5;241m.\u001b[39mcompressNN(inputs)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Decompress the weights\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m decompressed_weights \u001b[38;5;241m=\u001b[39m \u001b[43mcompNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompressNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompressed_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Compare the original weights with the decompressed weights\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# differences = compNN.compare_weights(original_weights, decompressed_weights)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# # Print the maximum difference for each weight matrix\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[88], line 38\u001b[0m, in \u001b[0;36mCompressibleNN.decompressNN\u001b[0;34m(self, compressed_weights)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Load the deserialized weights\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecompressed_weights.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 38\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Set the decompressed weights to the network\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet_model\u001b[38;5;241m.\u001b[39mset_weights(weights)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py:648\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    646\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(fobj, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m--> 648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mKeyError\u001b[0m: 51"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "class CompressibleNN(keras.Model):\n",
    "    def __init__(self, net_model):\n",
    "        super(CompressibleNN, self).__init__()\n",
    "        self.net_model = net_model\n",
    "        self.compressor = dahuffman.HuffmanCodec.from_data([])  # Initialize an empty compressor\n",
    "        \n",
    "    def compressNN(self, inputs):\n",
    "        # Get the current weights of the network\n",
    "        weights = self.net_model.get_weights()\n",
    "\n",
    "        # Serialize the weights using joblib\n",
    "        with open(\"weights.pkl\", \"wb\") as file:\n",
    "            joblib.dump(weights, file)\n",
    "\n",
    "        # Read the serialized weights\n",
    "        with open(\"weights.pkl\", \"rb\") as file:\n",
    "            serialized_weights = file.read()\n",
    "\n",
    "        # Compress the serialized weights using Huffman encoding\n",
    "        encoder = dahuffman.HuffmanCodec.from_data(serialized_weights)\n",
    "        compressed_weights = encoder.encode(serialized_weights)\n",
    "\n",
    "        return compressed_weights\n",
    "\n",
    "    def decompressNN(self, compressed_weights):\n",
    "        # Decode the compressed weights using Huffman decoding\n",
    "        decoder = dahuffman.HuffmanCodec.from_data(compressed_weights)\n",
    "        serialized_weights = decoder.decode(compressed_weights)\n",
    "\n",
    "        # Deserialize the weights using joblib\n",
    "        with open(\"decompressed_weights.pkl\", \"wb\") as file:\n",
    "            file.write(serialized_weights)\n",
    "\n",
    "        # Load the deserialized weights\n",
    "        with open(\"decompressed_weights.pkl\", \"rb\") as file:\n",
    "            weights = joblib.load(file)\n",
    "\n",
    "        # Set the decompressed weights to the network\n",
    "        self.net_model.set_weights(weights)\n",
    "\n",
    "        return self.net_model\n",
    "\n",
    "\n",
    "# Instantiate the CompressibleNN class and create the original model\n",
    "model = get_model()  # Replace with your own model creation code\n",
    "\n",
    "# Save the original model's architecture\n",
    "original_architecture = model.to_json()\n",
    "\n",
    "compNN = CompressibleNN(model)\n",
    "\n",
    "# Generate some random data for testing\n",
    "random_state = np.random.RandomState(42)  # Set the seed value to 42\n",
    "inputs = np.random.rand(10, 28, 28, 1)\n",
    "\n",
    "# Compress the weights\n",
    "compressed_weights = compNN.compressNN(inputs)\n",
    "\n",
    "# Decompress the weights\n",
    "decompressed_weights = compNN.decompressNN(compressed_weights)\n",
    "\n",
    "# Compare the original weights with the decompressed weights\n",
    "# differences = compNN.compare_weights(original_weights, decompressed_weights)\n",
    "\n",
    "# # Print the maximum difference for each weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16e96c-2803-49d9-8860-5b3c47c99b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
